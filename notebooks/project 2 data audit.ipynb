{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ceb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"output\"\n",
    "\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3675d963",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file= DATA_DIR / \"train_data.csv\"\n",
    "target_column=\"Class\"\n",
    "max_display=20\n",
    "high_corr_threshold=0.98\n",
    "nzv_ratio=0.01\n",
    "nzv_dominance=0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c44e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(data_file)\n",
    "num_rows,num_cols=data.shape\n",
    "print(f\"data loaded from {data_file}|shape= {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0666e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_column not in data.columns:\n",
    "    raise ValueError(f\"Target column '{target_column}' not found. Available columns: {list(data.columns)}\")\n",
    "\n",
    "target=data[target_column]\n",
    "features=data.drop(columns=[target_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8df444a",
   "metadata": {},
   "source": [
    "# Class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137915e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClass balance (counts and %):\")\n",
    "class_count=target.value_counts(dropna=False).rename(\"count\")\n",
    "class_pct=(class_count/len(target)*100).round(2).rename(\"percent\")\n",
    "class_balance=pd.concat([class_count,class_pct],axis=1)\n",
    "print(class_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34cf8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = OUTPUT_DIR / \"class_balance_summary.csv\"\n",
    "class_balance.to_csv(output_file, index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f614d32",
   "metadata": {},
   "source": [
    "# feature type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626ff20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features=features.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features=features.select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
    "boolean_features=features.select_dtypes(include=[\"bool\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a5d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_features=[]\n",
    "for col in features.columns:\n",
    "    if col in numeric_features or col in categorical_features or col in boolean_features:\n",
    "        continue\n",
    "    try:\n",
    "        _=pd.to_datetime(features[col].dropna().sample(min(1000,features[col].dropna().shape[0])),errors=\"raise\")\n",
    "        datetime_features.append(col)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf842dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nfeature type counts:\")\n",
    "print(pd.Series({\"total_features\":len(features.columns),\"numeric\":len(numeric_features),\n",
    "                 \"categorical\":len(categorical_features),\"boolean\":len(boolean_features),\"datetime_like\":len(datetime_features)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df17d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(numeric_features, name=\"numeric_features\") \\\n",
    "  .to_csv(OUTPUT_DIR / \"numeric_features.csv\", index=False)\n",
    "\n",
    "pd.Series(categorical_features, name=\"categorical_features\") \\\n",
    "  .to_csv(OUTPUT_DIR / \"categorical_features.csv\", index=False)\n",
    "\n",
    "pd.Series(boolean_features, name=\"boolean_features\") \\\n",
    "  .to_csv(OUTPUT_DIR / \"boolean_features.csv\", index=False)\n",
    "\n",
    "pd.Series(datetime_features, name=\"datetime_features\") \\\n",
    "  .to_csv(OUTPUT_DIR / \"datetime_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbba46dd",
   "metadata": {},
   "source": [
    "# missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134096a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_count=features.isna().sum()\n",
    "missing_pct=(missing_count/num_rows*100).round(3)\n",
    "missing_data=pd.DataFrame({\"missing_count\":missing_count,\"missing_percent\":missing_pct})\n",
    "missing_data=missing_data.sort_values(\"missing_percent\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c3475",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nfeatures with missing values:\")\n",
    "print(missing_data[missing_data[\"missing_count\"]>0].head(max_display))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5801c909",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = OUTPUT_DIR / \"missing_data_summary.csv\"\n",
    "missing_data.to_csv(output_file, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6e0288",
   "metadata": {},
   "source": [
    "# near-zero-variance features, Constant features, ID-like features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9312023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_nzv(column:pd.Series)->bool:\n",
    "    total=column.size\n",
    "    if total==0:\n",
    "        return False\n",
    "    unique_vals=column.dropna().unique()\n",
    "    unique_count=len(unique_vals)\n",
    "    if unique_count==0:\n",
    "        return False\n",
    "    unique_ratio=unique_count/total\n",
    "    counts=column.value_counts(dropna=True)\n",
    "    dominant_value_ratio=counts.iloc[0]/total if len(counts) else 0\n",
    "    return (unique_ratio<nzv_ratio) and (dominant_value_ratio>nzv_dominance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd7f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_features=[col for col in features.columns if features[col].nunique(dropna=False)==1]\n",
    "nzv_features=[]\n",
    "for col in features.columns:\n",
    "    try:\n",
    "        if is_nzv(features[col]):\n",
    "            nzv_features.append(col)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3829af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nConstant features (n={len(constant_features)}): {constant_features[:max_display]}\")\n",
    "print(f\"near-zero-variance features (n={len(nzv_features)}): {nzv_features[:max_display]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b2a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(constant_features,name=\"constant_features\") \\\n",
    "    .to_csv(OUTPUT_DIR / \"constant_features.csv\",index=False)\n",
    "pd.Series(nzv_features,name=\"nzv_features\") \\\n",
    "    .to_csv(OUTPUT_DIR / \"nzv_features.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f743b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_like_features=[]\n",
    "for col in features.columns:\n",
    "    num_unique=features[col].nunique(dropna=False)\n",
    "    if num_unique/num_rows>=0.999:\n",
    "        id_like_features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075885d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\npotential ID-like features (n={len(id_like_features)}): {id_like_features[:max_display]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1021602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(id_like_features,name=\"id_like_features\")\\\n",
    "    .to_csv(OUTPUT_DIR / \"id_like_features.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1260d1d",
   "metadata": {},
   "source": [
    "# duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a026c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows_count=data.duplicated().sum()\n",
    "print(f\"\\nduplicate rows found: {duplicate_rows_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55668e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_columns=[]\n",
    "column_map={}\n",
    "for col in features.columns:\n",
    "    key=pd.util.hash_pandas_object(features[col],index=False).values\n",
    "    key_bytes=key.tobytes()\n",
    "    if key_bytes in column_map:\n",
    "        duplicate_columns.append((column_map[key_bytes],col))\n",
    "    else:\n",
    "        column_map[key_bytes]=col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de6c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"duplicate column pairs: {duplicate_columns[:max_display]}\")\n",
    "pd.DataFrame(duplicate_columns,columns=[\"col_a\",\"col_b\"]) \\\n",
    "    .to_csv(OUTPUT_DIR / \"duplicate_columns.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac9501f",
   "metadata": {},
   "source": [
    "# high-correlation feature pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4e257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_corr_pairs=[]\n",
    "if len(numeric_features)>=2:\n",
    "    numeric_data=features[numeric_features].astype(\"float32\")\n",
    "    corr_matrix=numeric_data.corr(method=\"pearson\")\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1,len(corr_matrix.columns)):\n",
    "            corr_value=corr_matrix.iat[i,j]\n",
    "            if pd.notna(corr_value) and abs(corr_value)>=high_corr_threshold:\n",
    "                high_corr_pairs.append((corr_matrix.columns[i],corr_matrix.columns[j],float(corr_value)))\n",
    "high_corr_pairs.sort(key=lambda x:abs(x[2]),reverse=True)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c9cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nhigh-correlation feature pairs |r|>={high_corr_threshold} (showing up to {max_display}):\")\n",
    "print(high_corr_pairs[:max_display])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab8ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(high_corr_pairs,columns=[\"feature_a\",\"feature_b\",\"pearson_r\"]) \\\n",
    "    .to_csv(OUTPUT_DIR / \"high_correlation_pairs.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c47ee21",
   "metadata": {},
   "source": [
    "# numeric_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e4639",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc=features[numeric_features].describe().T\n",
    "output_file = OUTPUT_DIR / \"numeric_summary.csv\"\n",
    "desc.to_csv(output_file, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55627e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nsaved summary CSVs:\")\n",
    "print(\"1. class_balance_summary.csv\")\n",
    "print(\"2.numeric_features.csv\")\n",
    "print(\"3.categorical_features.csv\")\n",
    "print(\"4.boolean_features.csv\")\n",
    "print(\"5.datetime_features.csv\")\n",
    "print(\"6.missing_data_summary.csv\")\n",
    "print(\"7.constant_features.csv\")\n",
    "print(\"8.nzv_features.csv\")\n",
    "print(\"9.id_like_features.csv\")\n",
    "print(\"10.duplicate_columns.csv\")\n",
    "print(\"11.high_correlation_pairs.csv\")\n",
    "print(\"12numeric_summary.csv\")\n",
    "\n",
    "print(\"\\nData audit complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686996d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
